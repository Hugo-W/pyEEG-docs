

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>TRF on Syntactic Features &mdash; natMEEG 1.4.0a documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../_static/nbsphinx-code-cells.css?v=2aa19091" />

  
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=3c1f2aa2"></script>
      <script src="../_static/doctools.js?v=9bcbadda"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
      <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
      <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="author" title="About these documents" href="../about.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="IO module" href="../io.html" />
    <link rel="prev" title="Loading WordVectors as word level features" href="import_WordVectors.html" />
    <link href="../_static/style.css" rel="stylesheet" type="text/css">
     

</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            natMEEG
              <img src="../_static/natmeeg_logo_fulltransparent.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">To get started</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../install.html">Installation Instructions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../usage.html">Usage</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../tutorials.html">Tutorials</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../tutorials.html#loading-word-level-features">Loading Word-level features</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials.html#loading-word-vectors">Loading Word vectors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials.html#loading-processed-eeg-processed-by-eeglab">Loading processed EEG (processed by EEGLAB)</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../tutorials.html#jupyter-notebooks-examples">Jupyter Notebooks Examples</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="TRF_wordonsets.html">TRF Tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="CCA_envelope.html">CCA Tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="import_WordVectors.html">Loading WordVectors as word level features</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">TRF on Syntactic Features</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#Single-subject,-single-story">Single subject, single story</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Run-TRF-modelling">Run TRF modelling</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Average-several-models">Average several models</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Compute-one-big-model">Compute one <em>big</em> model</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Contents</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../io.html">IO module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../preprocess.html">Preprocessing module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models.html">Modelling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../utils.html">Utilities</a></li>
<li class="toctree-l1"><a class="reference internal" href="../simulate.html">Simulation module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../vizu.html">Vizualisaton</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Other</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../about.html">About natMEEG</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">natMEEG</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../tutorials.html">Tutorials</a></li>
      <li class="breadcrumb-item active">TRF on Syntactic Features</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/examples/TRF_syntactic_feats.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="TRF-on-Syntactic-Features">
<h1>TRF on Syntactic Features<a class="headerlink" href="#TRF-on-Syntactic-Features" title="Link to this heading"></a></h1>
<p>In this notebook we show how to import word onset as a word-level feature and compute TRF from them.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import os
from functools import reduce
from scipy.io import loadmat
from scipy.stats import zscore
from pyeeg.io import eeglab2mne
from pyeeg.models import TRFEstimator
import logging

# Set high logger level:
logging.getLogger().setLevel(logging.ERROR)

subj_id = 3 # id of participant (3 is subject P04)
story_id = 1 # id of stories (1 is AUNP02)
</pre></div>
</div>
</div>
<section id="Single-subject,-single-story">
<h2>Single subject, single story<a class="headerlink" href="#Single-subject,-single-story" title="Link to this heading"></a></h2>
<section id="Import-EEG">
<h3>Import EEG<a class="headerlink" href="#Import-EEG" title="Link to this heading"></a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>%gui qt

from PyQt5.QtWidgets import QFileDialog

def gui_fname(dir=None):
    &quot;&quot;&quot;Select a directory.&quot;&quot;&quot;
    if dir is None: dir =&#39;./&#39;
    fname = QFileDialog.getExistingDirectory(None, &quot;Select directory...&quot;, dir)
    return fname
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>try:
    experiment_path = &#39;/media/hw2512/SeagateExpansionDrive/EEG_data/Katerina_experiment&#39;
    os.listdir(&#39;/media/hw2512/SeagateExpansionDrive/EEG_data/Katerina_experiment&#39;)
except:
    experiment_path = gui_fname()
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>eeg_path = os.path.join(experiment_path, &quot;Processed/Fs-125/interp_bad/BP-0.3-65/Blink_pruned/&quot;)
list_subjects = os.listdir(eeg_path)
eeg_fname = [f for f in os.listdir(os.path.join(eeg_path, list_subjects[subj_id])) if f.endswith(&#39;.set&#39;)][0]

event_id = dict(boundary=-1, story_onset=1)
raw = eeglab2mne(os.path.join(eeg_path, list_subjects[subj_id], eeg_fname), load_ica=False, event_id=event_id)
raw.pick_types(eeg=True)

# Filtering the EEG
raw = raw.filter(1, 15, n_jobs=2)
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
1 events will be dropped because they occur on the same time sample as another event. `mne.io.Raw` objects store events on an event channel, which cannot represent two events on the same sample. You can extract the original event structure using `mne.io.eeglab.read_events_eeglab`. Then, you can e.g. subset the extracted events for constructing epochs.
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/home/hw2512/MachineLearning/Playground/EEG Analysis/pyEEG/pyeeg/io.py:184: RuntimeWarning: 1 events will be dropped because they occur on the same time sample as another event. `mne.io.Raw` objects store events on an event channel, which cannot represent two events on the same sample. You can extract the original event structure using `mne.io.eeglab.read_events_eeglab`. Then, you can e.g. subset the extracted events for constructing epochs.
  raw = mne.io.read_raw_eeglab(input_fname=fname, montage=montage_mne, event_id=event_id, preload=True)
</pre></div></div>
</div>
</section>
<section id="Import-Word-level-features">
<h3>Import Word-level features<a class="headerlink" href="#Import-Word-level-features" title="Link to this heading"></a></h3>
<p>We will load <em>surprisal</em> feature and fit a TRF model on both <em>word onsets</em> and <em>surprisal</em> word features.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Import all paths
from pyeeg.io import WordLevelFeatures, AlignedSpeech

stim_path = os.path.join(experiment_path, &#39;story_parts&#39;)
audio_path = os.path.join(stim_path, &#39;alignement_data/&#39;)
syntfeat_path = os.path.join(stim_path, &#39;syntactic_depth/&#39;)
list_synt_files = [item for item in os.listdir(syntfeat_path) if item.endswith(&#39;.csv&#39;)]
list_stories = [item.strip(&#39;_allsynt.csv&#39;) for item in list_synt_files]
list_audio_files = [os.path.join(audio_path, s, s + &#39;.wav&#39;) for s in list_stories]

# Sort them all in case:
for l in [list_audio_files, list_stories, list_synt_files]:
    l.sort()

onset_path = &#39;./all_katerina_onsets.mat&#39;
onsets = loadmat(onset_path)[&#39;onsets&#39;]

# Loading word onset and duration for AUNP02:
wo_path = os.path.join(syntfeat_path, list_synt_files[story_id])
duration_path = list_audio_files[story_id]
synt_path = os.path.join(syntfeat_path, list_synt_files[story_id])
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Create word-level feature object:
speech = AlignedSpeech(path_audio=duration_path, onset=onsets[subj_id, story_id], srate=raw.info[&#39;sfreq&#39;])
speech.create_word_level_features(use_wordonsets=True, path_syntactic=synt_path,
                                 path_wordonsets=wo_path)

# Creating feature matrix
x = speech.feats.get_values()

# Getting EEG data
y = raw.get_data()

# Croping data with indices that match current story for this participant
indices = speech.indices
y = y[:, indices].T
</pre></div>
</div>
</div>
</section>
</section>
<section id="Run-TRF-modelling">
<h2>Run TRF modelling<a class="headerlink" href="#Run-TRF-modelling" title="Link to this heading"></a></h2>
<p>The TRFEstimator class allows to use any arbitrary set of lags. The lagged time series design matrix will be generated when fitting the class instance to aligned EEG and feature data.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># TRF instance
reg_param = 0. # Ridge parameter
trf = TRFEstimator(tmin=-0.6, tmax=0.8, srate=raw.info[&#39;sfreq&#39;], alpha=reg_param)

# Fit our model
trf.fit(x, y, feat_names=[&quot;Word Onsets&quot;, &quot;Depth&quot;, &quot;Open&quot;, &quot;Close&quot;])
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
TRFEstimator(alpha=0.0, fit_intercept=True, srate=125.0,
       times=array([-0.592, -0.584, ...,  0.792,  0.8  ]), tmax=None,
       tmin=None)
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Plot model:
trf.plot(feat_id=range(trf.n_feats_), figsize=(12,3))
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_TRF_syntactic_feats_12_0.png" src="../_images/examples_TRF_syntactic_feats_12_0.png" />
</div>
</div>
</section>
<section id="Average-several-models">
<h2>Average several models<a class="headerlink" href="#Average-several-models" title="Link to this heading"></a></h2>
<p>Let’s loop the computation over all subjects and all stories to compute and grand average TRF.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>coefs = []

# Loop over subject
for subj_id, subj in enumerate(list_subjects):
    print(&quot;=&quot;*30 + &quot; Processing subject %s&quot;%(subj) + &quot;=&quot; * 20)
    eeg_fname = [f for f in os.listdir(os.path.join(eeg_path, list_subjects[subj_id])) if f.endswith(&#39;.set&#39;)][0]

    # Import and process EEG:
    raw = eeglab2mne(os.path.join(eeg_path, list_subjects[subj_id], eeg_fname), load_ica=False, event_id=event_id)
    raw.pick_types(eeg=True)
    raw = raw.filter(1, 15, n_jobs=2)
    y = raw.get_data()

    # Loop over stories
    for story_id, story in enumerate(list_stories):
        print(&quot;\t&quot;*4 + &quot;... %s&quot;%(story))
        wo_path = os.path.join(syntfeat_path, list_synt_files[story_id])
        duration_path = list_audio_files[story_id]
        synt_path = os.path.join(syntfeat_path, list_synt_files[story_id])

        # Create word-level feature object:
        speech = AlignedSpeech(path_audio=duration_path, onset=onsets[subj_id, story_id], srate=raw.info[&#39;sfreq&#39;])
        speech.create_word_level_features(use_wordonsets=True, path_syntactic=synt_path,
                                         path_wordonsets=wo_path)
        # Creating feature matrix
        x = speech.feats.get_values()
        # Croping data with indices that match current story for this participant
        indices = speech.indices

        # Perform the fit:
        trf = TRFEstimator(tmin=-0.6, tmax=0.8, srate=raw.info[&#39;sfreq&#39;], alpha=reg_param)
        trf.fit(x, y[:, indices].T, feat_names=[&quot;Word Onsets&quot;, &quot;Depth&quot;, &quot;Open&quot;, &quot;Close&quot;])

        coefs.append(trf.coef_)
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
============================== Processing subject P01_bis====================
                                ... AUNP01
                                ... AUNP02
                                ... AUNP03
                                ... AUNP04
                                ... AUNP05
                                ... AUNP06
                                ... AUNP07
                                ... AUNP08
                                ... BROP01
                                ... BROP02
                                ... BROP03
                                ... FLOP01
                                ... FLOP02
                                ... FLOP03
                                ... FLOP04
============================== Processing subject P02_11072016====================
1 events will be dropped because they occur on the same time sample as another event. `mne.io.Raw` objects store events on an event channel, which cannot represent two events on the same sample. You can extract the original event structure using `mne.io.eeglab.read_events_eeglab`. Then, you can e.g. subset the extracted events for constructing epochs.
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/home/hw2512/MachineLearning/Playground/EEG Analysis/pyEEG/pyeeg/io.py:184: RuntimeWarning: 1 events will be dropped because they occur on the same time sample as another event. `mne.io.Raw` objects store events on an event channel, which cannot represent two events on the same sample. You can extract the original event structure using `mne.io.eeglab.read_events_eeglab`. Then, you can e.g. subset the extracted events for constructing epochs.
  raw = mne.io.read_raw_eeglab(input_fname=fname, montage=montage_mne, event_id=event_id, preload=True)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
                                ... AUNP01
                                ... AUNP02
                                ... AUNP03
                                ... AUNP04
                                ... AUNP05
                                ... AUNP06
                                ... AUNP07
                                ... AUNP08
                                ... BROP01
                                ... BROP02
                                ... BROP03
                                ... FLOP01
                                ... FLOP02
                                ... FLOP03
                                ... FLOP04
============================== Processing subject P03_12072016====================
                                ... AUNP01
                                ... AUNP02
                                ... AUNP03
                                ... AUNP04
                                ... AUNP05
                                ... AUNP06
                                ... AUNP07
                                ... AUNP08
                                ... BROP01
                                ... BROP02
                                ... BROP03
                                ... FLOP01
                                ... FLOP02
                                ... FLOP03
                                ... FLOP04
============================== Processing subject P04_13072016====================
1 events will be dropped because they occur on the same time sample as another event. `mne.io.Raw` objects store events on an event channel, which cannot represent two events on the same sample. You can extract the original event structure using `mne.io.eeglab.read_events_eeglab`. Then, you can e.g. subset the extracted events for constructing epochs.
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/home/hw2512/MachineLearning/Playground/EEG Analysis/pyEEG/pyeeg/io.py:184: RuntimeWarning: 1 events will be dropped because they occur on the same time sample as another event. `mne.io.Raw` objects store events on an event channel, which cannot represent two events on the same sample. You can extract the original event structure using `mne.io.eeglab.read_events_eeglab`. Then, you can e.g. subset the extracted events for constructing epochs.
  raw = mne.io.read_raw_eeglab(input_fname=fname, montage=montage_mne, event_id=event_id, preload=True)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
                                ... AUNP01
                                ... AUNP02
                                ... AUNP03
                                ... AUNP04
                                ... AUNP05
                                ... AUNP06
                                ... AUNP07
                                ... AUNP08
                                ... BROP01
                                ... BROP02
                                ... BROP03
                                ... FLOP01
                                ... FLOP02
                                ... FLOP03
                                ... FLOP04
============================== Processing subject P05_14072016====================
1 events will be dropped because they occur on the same time sample as another event. `mne.io.Raw` objects store events on an event channel, which cannot represent two events on the same sample. You can extract the original event structure using `mne.io.eeglab.read_events_eeglab`. Then, you can e.g. subset the extracted events for constructing epochs.
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/home/hw2512/MachineLearning/Playground/EEG Analysis/pyEEG/pyeeg/io.py:184: RuntimeWarning: 1 events will be dropped because they occur on the same time sample as another event. `mne.io.Raw` objects store events on an event channel, which cannot represent two events on the same sample. You can extract the original event structure using `mne.io.eeglab.read_events_eeglab`. Then, you can e.g. subset the extracted events for constructing epochs.
  raw = mne.io.read_raw_eeglab(input_fname=fname, montage=montage_mne, event_id=event_id, preload=True)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
                                ... AUNP01
                                ... AUNP02
                                ... AUNP03
                                ... AUNP04
                                ... AUNP05
                                ... AUNP06
                                ... AUNP07
                                ... AUNP08
                                ... BROP01
                                ... BROP02
                                ... BROP03
                                ... FLOP01
                                ... FLOP02
                                ... FLOP03
                                ... FLOP04
============================== Processing subject P06_18072016====================
                                ... AUNP01
                                ... AUNP02
                                ... AUNP03
                                ... AUNP04
                                ... AUNP05
                                ... AUNP06
                                ... AUNP07
                                ... AUNP08
                                ... BROP01
                                ... BROP02
                                ... BROP03
                                ... FLOP01
                                ... FLOP02
                                ... FLOP03
                                ... FLOP04
============================== Processing subject P07_19072016====================
                                ... AUNP01
                                ... AUNP02
                                ... AUNP03
                                ... AUNP04
                                ... AUNP05
                                ... AUNP06
                                ... AUNP07
                                ... AUNP08
                                ... BROP01
                                ... BROP02
                                ... BROP03
                                ... FLOP01
                                ... FLOP02
                                ... FLOP03
                                ... FLOP04
============================== Processing subject P08_21072016====================
1 events will be dropped because they occur on the same time sample as another event. `mne.io.Raw` objects store events on an event channel, which cannot represent two events on the same sample. You can extract the original event structure using `mne.io.eeglab.read_events_eeglab`. Then, you can e.g. subset the extracted events for constructing epochs.
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/home/hw2512/MachineLearning/Playground/EEG Analysis/pyEEG/pyeeg/io.py:184: RuntimeWarning: 1 events will be dropped because they occur on the same time sample as another event. `mne.io.Raw` objects store events on an event channel, which cannot represent two events on the same sample. You can extract the original event structure using `mne.io.eeglab.read_events_eeglab`. Then, you can e.g. subset the extracted events for constructing epochs.
  raw = mne.io.read_raw_eeglab(input_fname=fname, montage=montage_mne, event_id=event_id, preload=True)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
                                ... AUNP01
                                ... AUNP02
                                ... AUNP03
                                ... AUNP04
                                ... AUNP05
                                ... AUNP06
                                ... AUNP07
                                ... AUNP08
                                ... BROP01
                                ... BROP02
                                ... BROP03
                                ... FLOP01
                                ... FLOP02
                                ... FLOP03
                                ... FLOP04
============================== Processing subject P09_22072016====================
1 events will be dropped because they occur on the same time sample as another event. `mne.io.Raw` objects store events on an event channel, which cannot represent two events on the same sample. You can extract the original event structure using `mne.io.eeglab.read_events_eeglab`. Then, you can e.g. subset the extracted events for constructing epochs.
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/home/hw2512/MachineLearning/Playground/EEG Analysis/pyEEG/pyeeg/io.py:184: RuntimeWarning: 1 events will be dropped because they occur on the same time sample as another event. `mne.io.Raw` objects store events on an event channel, which cannot represent two events on the same sample. You can extract the original event structure using `mne.io.eeglab.read_events_eeglab`. Then, you can e.g. subset the extracted events for constructing epochs.
  raw = mne.io.read_raw_eeglab(input_fname=fname, montage=montage_mne, event_id=event_id, preload=True)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
                                ... AUNP01
                                ... AUNP02
                                ... AUNP03
                                ... AUNP04
                                ... AUNP05
                                ... AUNP06
                                ... AUNP07
                                ... AUNP08
                                ... BROP01
                                ... BROP02
                                ... BROP03
                                ... FLOP01
                                ... FLOP02
                                ... FLOP03
                                ... FLOP04
============================== Processing subject P10_14092016====================
                                ... AUNP01
                                ... AUNP02
                                ... AUNP03
                                ... AUNP04
                                ... AUNP05
                                ... AUNP06
                                ... AUNP07
                                ... AUNP08
                                ... BROP01
                                ... BROP02
                                ... BROP03
                                ... FLOP01
                                ... FLOP02
                                ... FLOP03
                                ... FLOP04
============================== Processing subject P12_01092016====================
                                ... AUNP01
                                ... AUNP02
                                ... AUNP03
                                ... AUNP04
                                ... AUNP05
                                ... AUNP06
                                ... AUNP07
                                ... AUNP08
                                ... BROP01
                                ... BROP02
                                ... BROP03
                                ... FLOP01
                                ... FLOP02
                                ... FLOP03
                                ... FLOP04
============================== Processing subject P13_08092016====================
                                ... AUNP01
                                ... AUNP02
                                ... AUNP03
                                ... AUNP04
                                ... AUNP05
                                ... AUNP06
                                ... AUNP07
                                ... AUNP08
                                ... BROP01
                                ... BROP02
                                ... BROP03
                                ... FLOP01
                                ... FLOP02
                                ... FLOP03
                                ... FLOP04
============================== Processing subject P14_21032017====================
                                ... AUNP01
                                ... AUNP02
                                ... AUNP03
                                ... AUNP04
                                ... AUNP05
                                ... AUNP06
                                ... AUNP07
                                ... AUNP08
                                ... BROP01
                                ... BROP02
                                ... BROP03
                                ... FLOP01
                                ... FLOP02
                                ... FLOP03
                                ... FLOP04
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Average and plug the resulting coef in trf instance for easy plotting
coef_avg = np.mean(np.asarray(coefs), axis=0)
trf.coef_ = coef_avg

trf.plot(feat_id=range(trf.n_feats_), figsize=(14,3))
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_TRF_syntactic_feats_15_0.png" src="../_images/examples_TRF_syntactic_feats_15_0.png" />
</div>
</div>
</section>
<section id="Compute-one-big-model">
<h2>Compute one <em>big</em> model<a class="headerlink" href="#Compute-one-big-model" title="Link to this heading"></a></h2>
<p>Now, instead of computing a model for each story and each participants, we will compute one <em>grand</em> model trained on the concatenation of all data.</p>
<p><strong>But…</strong> This is very greedy in memory. Indeed, storing all the EEG data results in a matrix of roughly 2Gb, then the matrix of features, for two features is approximately 100mb, which then results in a design matrix (i.e. time-lagged version of the features) of 12Gb. The latter is then used in different computation, svd or least-square esitmation, which may involve another copy of the matrix… Hence the memory usage can reach a total of 26Gb!!</p>
<p>However it will give a more robust estimate of the TRFs. Fortunately, the implementation of our TRF estimator, allows for a memory-efficient way to compute the coefficient.</p>
<p>The trick used is to accumulate the covariance and cross-covariance matrices used to compute the pseudo-inverse to fit the model. Thus we cut the bulk of the computation (SVD computation) in smaller pieces. Also it can be noted that since the target is always the same (word from stories, similar across participants) the concatenated word-level features can be stored only once and reused to compute the other matrices.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Loop over stories to get a big concatenation of each story&#39;s word features
X = []
wf = {} # make a dictionnary of those, keys are story id
for story_id, story in enumerate(list_stories):
    print(&quot;Loading story&#39;s word features for ... %s&quot;%(story))
    wo_path = os.path.join(syntfeat_path, list_synt_files[story_id])
    duration_path = list_audio_files[story_id]
    synt_path = os.path.join(syntfeat_path, list_synt_files[story_id])

    # Create word-level feature object:
    wf[story] = WordLevelFeatures(path_audio=duration_path, path_wordonsets=wo_path, path_syntactic=synt_path)
    X.append(wf[story].align_word_features(srate=raw.info[&#39;sfreq&#39;], features=(&#39;depth&#39;,&#39;open&#39;,&#39;close&#39;)))

X = np.concatenate(X)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Loading story&#39;s word features for ... AUNP01
Loading story&#39;s word features for ... AUNP02
Loading story&#39;s word features for ... AUNP03
Loading story&#39;s word features for ... AUNP04
Loading story&#39;s word features for ... AUNP05
Loading story&#39;s word features for ... AUNP06
Loading story&#39;s word features for ... AUNP07
Loading story&#39;s word features for ... AUNP08
Loading story&#39;s word features for ... BROP01
Loading story&#39;s word features for ... BROP02
Loading story&#39;s word features for ... BROP03
Loading story&#39;s word features for ... FLOP01
Loading story&#39;s word features for ... FLOP02
Loading story&#39;s word features for ... FLOP03
Loading story&#39;s word features for ... FLOP04
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Loop over subject
Y = []
for subj_id, subj in enumerate(list_subjects):
    print(&quot;=&quot;*30 + &quot; Processing subject %s&quot;%(subj) + &quot;=&quot; * 20)
    eeg_fname = [f for f in os.listdir(os.path.join(eeg_path, list_subjects[subj_id])) if f.endswith(&#39;.set&#39;)][0]

    # Import and process EEG:
    raw = eeglab2mne(os.path.join(eeg_path, list_subjects[subj_id], eeg_fname), load_ica=False, event_id=event_id)
    raw.pick_types(eeg=True)
    raw = raw.filter(1, 15, n_jobs=2)
    y = raw.get_data()
    indices = reduce(lambda x,y: x + y, [AlignedSpeech(path_audio=list_audio_files[story_id],
                                                       onset=onsets[subj_id, story_id], srate=raw.info[&#39;sfreq&#39;]) for story_id, story in enumerate(list_stories)]).indices
    Y.append(zscore(y[:, indices].T))
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
============================== Processing subject P01_bis====================
============================== Processing subject P02_11072016====================
1 events will be dropped because they occur on the same time sample as another event. `mne.io.Raw` objects store events on an event channel, which cannot represent two events on the same sample. You can extract the original event structure using `mne.io.eeglab.read_events_eeglab`. Then, you can e.g. subset the extracted events for constructing epochs.
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/home/hw2512/MachineLearning/Playground/EEG Analysis/pyEEG/pyeeg/io.py:184: RuntimeWarning: 1 events will be dropped because they occur on the same time sample as another event. `mne.io.Raw` objects store events on an event channel, which cannot represent two events on the same sample. You can extract the original event structure using `mne.io.eeglab.read_events_eeglab`. Then, you can e.g. subset the extracted events for constructing epochs.
  raw = mne.io.read_raw_eeglab(input_fname=fname, montage=montage_mne, event_id=event_id, preload=True)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
============================== Processing subject P03_12072016====================
============================== Processing subject P04_13072016====================
1 events will be dropped because they occur on the same time sample as another event. `mne.io.Raw` objects store events on an event channel, which cannot represent two events on the same sample. You can extract the original event structure using `mne.io.eeglab.read_events_eeglab`. Then, you can e.g. subset the extracted events for constructing epochs.
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/home/hw2512/MachineLearning/Playground/EEG Analysis/pyEEG/pyeeg/io.py:184: RuntimeWarning: 1 events will be dropped because they occur on the same time sample as another event. `mne.io.Raw` objects store events on an event channel, which cannot represent two events on the same sample. You can extract the original event structure using `mne.io.eeglab.read_events_eeglab`. Then, you can e.g. subset the extracted events for constructing epochs.
  raw = mne.io.read_raw_eeglab(input_fname=fname, montage=montage_mne, event_id=event_id, preload=True)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
============================== Processing subject P05_14072016====================
1 events will be dropped because they occur on the same time sample as another event. `mne.io.Raw` objects store events on an event channel, which cannot represent two events on the same sample. You can extract the original event structure using `mne.io.eeglab.read_events_eeglab`. Then, you can e.g. subset the extracted events for constructing epochs.
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/home/hw2512/MachineLearning/Playground/EEG Analysis/pyEEG/pyeeg/io.py:184: RuntimeWarning: 1 events will be dropped because they occur on the same time sample as another event. `mne.io.Raw` objects store events on an event channel, which cannot represent two events on the same sample. You can extract the original event structure using `mne.io.eeglab.read_events_eeglab`. Then, you can e.g. subset the extracted events for constructing epochs.
  raw = mne.io.read_raw_eeglab(input_fname=fname, montage=montage_mne, event_id=event_id, preload=True)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
============================== Processing subject P06_18072016====================
============================== Processing subject P07_19072016====================
============================== Processing subject P08_21072016====================
1 events will be dropped because they occur on the same time sample as another event. `mne.io.Raw` objects store events on an event channel, which cannot represent two events on the same sample. You can extract the original event structure using `mne.io.eeglab.read_events_eeglab`. Then, you can e.g. subset the extracted events for constructing epochs.
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/home/hw2512/MachineLearning/Playground/EEG Analysis/pyEEG/pyeeg/io.py:184: RuntimeWarning: 1 events will be dropped because they occur on the same time sample as another event. `mne.io.Raw` objects store events on an event channel, which cannot represent two events on the same sample. You can extract the original event structure using `mne.io.eeglab.read_events_eeglab`. Then, you can e.g. subset the extracted events for constructing epochs.
  raw = mne.io.read_raw_eeglab(input_fname=fname, montage=montage_mne, event_id=event_id, preload=True)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
============================== Processing subject P09_22072016====================
1 events will be dropped because they occur on the same time sample as another event. `mne.io.Raw` objects store events on an event channel, which cannot represent two events on the same sample. You can extract the original event structure using `mne.io.eeglab.read_events_eeglab`. Then, you can e.g. subset the extracted events for constructing epochs.
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/home/hw2512/MachineLearning/Playground/EEG Analysis/pyEEG/pyeeg/io.py:184: RuntimeWarning: 1 events will be dropped because they occur on the same time sample as another event. `mne.io.Raw` objects store events on an event channel, which cannot represent two events on the same sample. You can extract the original event structure using `mne.io.eeglab.read_events_eeglab`. Then, you can e.g. subset the extracted events for constructing epochs.
  raw = mne.io.read_raw_eeglab(input_fname=fname, montage=montage_mne, event_id=event_id, preload=True)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
============================== Processing subject P10_14092016====================
============================== Processing subject P12_01092016====================
============================== Processing subject P13_08092016====================
============================== Processing subject P14_21032017====================
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[27]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Perform the fit:
trf = TRFEstimator(tmin=-0.6, tmax=0.8, srate=raw.info[&#39;sfreq&#39;], alpha=0.)
trf.fit(X, Y, feat_names=[&quot;Word Onsets&quot;, &quot;Depth&quot;, &quot;Open&quot;, &quot;Close&quot;])
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[27]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
TRFEstimator(alpha=0.0, fit_intercept=True, srate=125.0,
       times=array([-0.592, -0.584, ...,  0.792,  0.8  ]), tmax=None,
       tmin=None)
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[29]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>trf.plot(feat_id=[0,1,2,3], figsize=(14,3))
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_TRF_syntactic_feats_20_0.png" src="../_images/examples_TRF_syntactic_feats_20_0.png" />
</div>
</div>
<section id="Comparing-with-MNE-ReceptiveField">
<h3>Comparing with MNE-ReceptiveField<a class="headerlink" href="#Comparing-with-MNE-ReceptiveField" title="Link to this heading"></a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[30]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from mne.decoding import ReceptiveField, TimeDelayingRidge
from sklearn.model_selection import KFold
from sklearn.preprocessing import normalize as zscore
import mne
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[32]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Define the delays that we will use in the receptive field
tmin, tmax = -.6, .8
feat_name = [&quot;Word Onsets&quot;, &quot;Depth&quot;, &quot;Open&quot;, &quot;Close&quot;]
n_feats = len(feat_name)
sfreq = raw.info[&#39;sfreq&#39;]

# Initialize the model
estimator = TimeDelayingRidge(tmin, tmax, sfreq, #reg_type=&#39;laplacian&#39;,
                                  alpha=1e-4)
rf = ReceptiveField(tmin, tmax, raw.info[&#39;sfreq&#39;], feature_names=feat_name,
                    estimator=estimator, scoring=&#39;r2&#39;)
# We&#39;ll have (tmax - tmin) * sfreq delays
# and an extra 2 delays since we are inclusive on the beginning / end index
n_delays = int((tmax - tmin) * sfreq) + 1
n_channels = 64

n_splits = 5
cv = KFold(n_splits)

mean_coefs = np.zeros((len(list_subjects), n_channels, n_feats, n_delays))
mean_scores = np.zeros((len(list_subjects), n_channels))

for subj in range(len(list_subjects)):
    print(&quot;Estimation of coefficients for subject {:s}&quot;.format(list_subjects[subj]))
    list_datafiles = os.listdir(os.path.join(eeg_path, list_subjects[subj]))
    eeg_fname = [f for f in list_datafiles if f.endswith(&#39;.set&#39;)][0]
    eeg = mne.io.eeglab.read_raw_eeglab(input_fname=os.path.join(eeg_path, list_subjects[subj], eeg_fname), montage=&#39;standard_1020&#39;, event_id=event_id, preload=True)

    eeg.filter(1, 15, h_trans_bandwidth=2, n_jobs=-1)

    y = eeg.copy().pick_types(eeg=True).get_data()
    indices = reduce(lambda x,y: x + y, [AlignedSpeech(path_audio=list_audio_files[story_id],
                                                       onset=onsets[subj, story_id], srate=raw.info[&#39;sfreq&#39;]) for story_id, story in enumerate(list_stories)]).indices

    # Prepare model data (make time the first dimension)
    y = y[:, indices]  # Outputs for the model
    y = zscore(y.T)

    # Iterate through splits, fit the model, and predict/test on held-out data
    coefs = np.zeros((n_splits, n_channels, n_feats, n_delays))
    scores = np.zeros((n_splits, n_channels))
    for ii, (train, test) in enumerate(cv.split(X)):
        print(&#39;split %s / %s&#39; % (ii + 1, n_splits))
        rf.fit(X[train], y[train])
        scores[ii] = rf.score(X[test], y[test])
        # coef_ is shape (n_outputs, n_features, n_delays)
        coefs[ii] = rf.coef_
    times = rf.delays_ / float(rf.sfreq)

    # Average scores and coefficients across CV splits
    mean_coefs[subj] = coefs.mean(axis=0)
    mean_scores[subj,:] = scores.mean(axis=0)
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Estimation of coefficients for subject P01_bis
split 1 / 5
split 2 / 5
split 3 / 5
split 4 / 5
split 5 / 5
Estimation of coefficients for subject P02_11072016
1 events will be dropped because they occur on the same time sample as another event. `mne.io.Raw` objects store events on an event channel, which cannot represent two events on the same sample. You can extract the original event structure using `mne.io.eeglab.read_events_eeglab`. Then, you can e.g. subset the extracted events for constructing epochs.
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
&lt;ipython-input-32-2e5065e9feea&gt;:27: RuntimeWarning: 1 events will be dropped because they occur on the same time sample as another event. `mne.io.Raw` objects store events on an event channel, which cannot represent two events on the same sample. You can extract the original event structure using `mne.io.eeglab.read_events_eeglab`. Then, you can e.g. subset the extracted events for constructing epochs.
  eeg = mne.io.eeglab.read_raw_eeglab(input_fname=os.path.join(eeg_path, list_subjects[subj], eeg_fname), montage=&#39;standard_1020&#39;, event_id=event_id, preload=True)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
split 1 / 5
split 2 / 5
split 3 / 5
split 4 / 5
split 5 / 5
Estimation of coefficients for subject P03_12072016
split 1 / 5
split 2 / 5
split 3 / 5
split 4 / 5
split 5 / 5
Estimation of coefficients for subject P04_13072016
1 events will be dropped because they occur on the same time sample as another event. `mne.io.Raw` objects store events on an event channel, which cannot represent two events on the same sample. You can extract the original event structure using `mne.io.eeglab.read_events_eeglab`. Then, you can e.g. subset the extracted events for constructing epochs.
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
&lt;ipython-input-32-2e5065e9feea&gt;:27: RuntimeWarning: 1 events will be dropped because they occur on the same time sample as another event. `mne.io.Raw` objects store events on an event channel, which cannot represent two events on the same sample. You can extract the original event structure using `mne.io.eeglab.read_events_eeglab`. Then, you can e.g. subset the extracted events for constructing epochs.
  eeg = mne.io.eeglab.read_raw_eeglab(input_fname=os.path.join(eeg_path, list_subjects[subj], eeg_fname), montage=&#39;standard_1020&#39;, event_id=event_id, preload=True)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
split 1 / 5
split 2 / 5
split 3 / 5
split 4 / 5
split 5 / 5
Estimation of coefficients for subject P05_14072016
1 events will be dropped because they occur on the same time sample as another event. `mne.io.Raw` objects store events on an event channel, which cannot represent two events on the same sample. You can extract the original event structure using `mne.io.eeglab.read_events_eeglab`. Then, you can e.g. subset the extracted events for constructing epochs.
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
&lt;ipython-input-32-2e5065e9feea&gt;:27: RuntimeWarning: 1 events will be dropped because they occur on the same time sample as another event. `mne.io.Raw` objects store events on an event channel, which cannot represent two events on the same sample. You can extract the original event structure using `mne.io.eeglab.read_events_eeglab`. Then, you can e.g. subset the extracted events for constructing epochs.
  eeg = mne.io.eeglab.read_raw_eeglab(input_fname=os.path.join(eeg_path, list_subjects[subj], eeg_fname), montage=&#39;standard_1020&#39;, event_id=event_id, preload=True)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
split 1 / 5
split 2 / 5
split 3 / 5
split 4 / 5
split 5 / 5
Estimation of coefficients for subject P06_18072016
split 1 / 5
split 2 / 5
split 3 / 5
split 4 / 5
split 5 / 5
Estimation of coefficients for subject P07_19072016
split 1 / 5
split 2 / 5
split 3 / 5
split 4 / 5
split 5 / 5
Estimation of coefficients for subject P08_21072016
1 events will be dropped because they occur on the same time sample as another event. `mne.io.Raw` objects store events on an event channel, which cannot represent two events on the same sample. You can extract the original event structure using `mne.io.eeglab.read_events_eeglab`. Then, you can e.g. subset the extracted events for constructing epochs.
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
&lt;ipython-input-32-2e5065e9feea&gt;:27: RuntimeWarning: 1 events will be dropped because they occur on the same time sample as another event. `mne.io.Raw` objects store events on an event channel, which cannot represent two events on the same sample. You can extract the original event structure using `mne.io.eeglab.read_events_eeglab`. Then, you can e.g. subset the extracted events for constructing epochs.
  eeg = mne.io.eeglab.read_raw_eeglab(input_fname=os.path.join(eeg_path, list_subjects[subj], eeg_fname), montage=&#39;standard_1020&#39;, event_id=event_id, preload=True)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
split 1 / 5
split 2 / 5
split 3 / 5
split 4 / 5
split 5 / 5
Estimation of coefficients for subject P09_22072016
1 events will be dropped because they occur on the same time sample as another event. `mne.io.Raw` objects store events on an event channel, which cannot represent two events on the same sample. You can extract the original event structure using `mne.io.eeglab.read_events_eeglab`. Then, you can e.g. subset the extracted events for constructing epochs.
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
&lt;ipython-input-32-2e5065e9feea&gt;:27: RuntimeWarning: 1 events will be dropped because they occur on the same time sample as another event. `mne.io.Raw` objects store events on an event channel, which cannot represent two events on the same sample. You can extract the original event structure using `mne.io.eeglab.read_events_eeglab`. Then, you can e.g. subset the extracted events for constructing epochs.
  eeg = mne.io.eeglab.read_raw_eeglab(input_fname=os.path.join(eeg_path, list_subjects[subj], eeg_fname), montage=&#39;standard_1020&#39;, event_id=event_id, preload=True)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
split 1 / 5
split 2 / 5
split 3 / 5
split 4 / 5
split 5 / 5
Estimation of coefficients for subject P10_14092016
split 1 / 5
split 2 / 5
split 3 / 5
split 4 / 5
split 5 / 5
Estimation of coefficients for subject P12_01092016
split 1 / 5
split 2 / 5
split 3 / 5
split 4 / 5
split 5 / 5
Estimation of coefficients for subject P13_08092016
split 1 / 5
split 2 / 5
split 3 / 5
split 4 / 5
split 5 / 5
Estimation of coefficients for subject P14_21032017
split 1 / 5
split 2 / 5
split 3 / 5
split 4 / 5
split 5 / 5
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[34]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>grand_avg_coefs = mean_coefs.mean(0)
cmap=&#39;Spectral_r&#39;

# Print mean coefficients across all time delays / channels (see Fig 1 in [1])
time_plot = [0.072, 0.300, 0.350, 0.050]  # For highlighting a specific time.
fig, ax = plt.subplots(figsize=(12, n_feats * 4), ncols=2, nrows=n_feats, gridspec_kw=dict(wspace=0.5, hspace=.5))
for k, f_name in enumerate(feat_name):
    max_coef = grand_avg_coefs[:, k, :].max()
    #ax[0].pcolormesh(times, ix_chs, mean_coefs, cmap=cmap,
    #              vmin=-max_coef, vmax=max_coef, shading=&#39;gouraud&#39;)
    ax[k, 0].plot(times, grand_avg_coefs[:, k, :].T);
    ax[k, 0].axvline(time_plot[k], ls=&#39;--&#39;, color=&#39;w&#39;, lw=2)
    ax[k, 0].set(xlabel=&#39;Delay (s)&#39;, ylabel=&#39;Amplitude (a.u.)&#39;, title=f_name)
    plt.setp(ax[k, 0].get_xticklabels(), rotation=45)
    #mne.viz.tight_layout()

    # Make a topographic map of coefficients for a given delay (see Fig 2C in [1])
    ix_plot = np.argmin(np.abs(time_plot[k] - times))
    im, _ = mne.viz.plot_topomap(grand_avg_coefs[:, k, ix_plot], pos=eeg.info, axes=ax[k, 1], show=False, contours=0,
                         vmin=-max_coef, vmax=max_coef, cmap=cmap, res=100)
    plt.colorbar(im, ax=ax[k, 1])
    # Transform head contour in white:
    lines = ax[k, 1].get_lines()
    for L in lines:
        L.set_color(&#39;w&#39;)
    ax[k, 1].set(title=&quot;Topomap of model coefficients\nfor delay %s&quot; % time_plot[k])
#mne.viz.tight_layout()
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_TRF_syntactic_feats_24_0.png" src="../_images/examples_TRF_syntactic_feats_24_0.png" />
</div>
</div>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="import_WordVectors.html" class="btn btn-neutral float-left" title="Loading WordVectors as word level features" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../io.html" class="btn btn-neutral float-right" title="IO module" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Hugo Weissbart.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>